digraph cluster_main {
	graph [label=main]
	subgraph cluster_mod {
		label=mod
		1 [label="block:1@1
for epoch in range(1, epochs + 1)::Line 1
"]
		2 [label="block:2@2
for i, data in enumerate(trainloader, 0)::Line 2
"]
		4 [label="block:4@5
inputs, labels = data:Line 5
optimizer.zero_grad():Line 8
outputs = net(inputs):Line 11
loss = criterion(outputs, labels.flatten()):Line 12
loss.backward():Line 13
optimizer.step():Line 14
running_loss += loss.item():Line 17
if i % 2000 == 1999::Line 18
"]
		6 [label="block:6@21
training_loss.append(running_loss / 2000):Line 21
with torch.no_grad()::Line 24
"]
		8 [label="block:8@25
running_val_loss = 0.0:Line 25
"]
		10 [label="block:10@26
for i_val, data_val in enumerate(valloader, 0)::Line 26
"]
		11 [label="block:11@27
inputs_val, labels_val = data_val:Line 27
outputs_val = net(inputs_val):Line 28
loss_val = criterion(outputs_val, labels_val.flatten()).item():Line 29
running_val_loss += loss_val:Line 30
"]
		11 -> 10
		10 -> 11 [label=<ast.Call object at 0x000001C5F1F3E890>]
		9 [label="block:9@31
validation_loss.append(running_val_loss / len(valloader)):Line 31
print('[%d, %5d] train_loss: %.3f | val_loss: %.3f' % (epoch, i + 1,     running_loss / 2000, running_val_loss / len(valloader))):Line 33
torch.save({'epoch': epoch, 'model_state_dict': net.state_dict(),    'optimizer_state_dict': optimizer.state_dict(), 'training_loss':     running_loss / 2000, 'validation_loss': running_val_loss / len(    valloader)}, PATH + '/epoch{}_model.pt'.format(epoch)):Line 37
running_loss = 0.0:Line 45
"]
		9 -> 2
		10 -> 9
		8 -> 10
		6 -> 8
		4 -> 6 [label=<ast.Compare object at 0x000001C5F1F3EE30>]
		4 -> 2 [label=<ast.Compare object at 0x000001C5F1F3CD30>]
		2 -> 4 [label=<ast.Call object at 0x000001C5F1F3F640>]
		2 -> 1
		1 -> 2 [label=<ast.Call object at 0x000001C5F1EE79A0>]
	}
}
